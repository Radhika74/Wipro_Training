{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfea4609",
   "metadata": {},
   "source": [
    "Perform Text Preprocessing on SMSSpamCollection Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4db100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            message  \\\n",
      "0      0  Go until jurong point, crazy.. Available only ...   \n",
      "1      0                      Ok lar... Joking wif u oni...   \n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3      0  U dun say so early hor... U c already then say...   \n",
      "4      0  Nah I don't think he goes to usf, he lives aro...   \n",
      "5      1  FreeMsg Hey there darling it's been 3 week's n...   \n",
      "6      0  Even my brother is not like to speak with me. ...   \n",
      "7      0  As per your request 'Melle Melle (Oru Minnamin...   \n",
      "8      1  WINNER!! As a valued network customer you have...   \n",
      "9      1  Had your mobile 11 months or more? U R entitle...   \n",
      "\n",
      "                                       clean_message  \n",
      "0  go jurong point crazi avail bugi n great world...  \n",
      "1                              ok lar joke wif u oni  \n",
      "2  free entri wkli comp win fa cup final tkt st m...  \n",
      "3                u dun say earli hor u c alreadi say  \n",
      "4               nah think goe usf live around though  \n",
      "5  freemsg hey darl week word back like fun still...  \n",
      "6      even brother like speak treat like aid patent  \n",
      "7  per request mell mell oru minnaminungint nurun...  \n",
      "8  winner valu network custom select receivea pri...  \n",
      "9  mobil month u r entitl updat latest colour mob...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "df = df[[\"v1\", \"v2\"]]\n",
    "df.columns = [\"label\", \"message\"]\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z]\", \" \", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [ps.stem(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"clean_message\"] = df[\"message\"].apply(preprocess_text)\n",
    "print(df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
